{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module load meme/5.0.1\n",
    "bases = ['A', 'T', 'C', 'G']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Shuffled Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    if not os.path.isdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/' + cluster):\n",
    "        os.mkdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/' + cluster)\n",
    "    for j in range(10):\n",
    "        meme_cmd = 'fasta-shuffle-letters -kmer 2 -dna -line 1500 /mnt/lab_data3/soumyak/adpd/fasta_inputs/' \\\n",
    "                    + cluster + '.' + 'noneffect.fasta /oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/' \\\n",
    "                    + cluster + '/' + 'shuf' + str(j) + '.initial.fasta'\n",
    "        meme_cmd = meme_cmd.split()\n",
    "        #print(meme_cmd)\n",
    "        ret = subprocess.call(meme_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Variant Position (at Position 499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    snps = pd.read_csv('/mnt/lab_data3/soumyak/adpd/snp_lists/'+cluster+'.overlap.expanded.snps.hg38.bed',\n",
    "                       sep='\\t')\n",
    "    with open('/mnt/lab_data3/soumyak/adpd/fasta_inputs/'+cluster+'.noneffect.fasta', 'r') as noneffect_file, \\\n",
    "         open('/mnt/lab_data3/soumyak/adpd/fasta_inputs/'+cluster+'.effect.fasta', 'r') as effect_file:\n",
    "        noneffect_seqs = noneffect_file.readlines()\n",
    "        effect_seqs = effect_file.readlines()\n",
    "        for index, row in snps.iterrows():\n",
    "            rsid = row['rsid']\n",
    "            noneffect = row['noneffect']\n",
    "            effect = row['effect']\n",
    "            if effect.upper() in bases and noneffect.upper() in bases:\n",
    "                #print(noneffect)\n",
    "                #print(noneffect_seqs[(2 * index) + 1][499])\n",
    "                assert(noneffect_seqs[(2 * index) + 1][499] == noneffect)\n",
    "                assert(effect_seqs[(2 * index) + 1][499] == effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 1kb Shuffled Allele Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    snps = pd.read_csv('/mnt/lab_data3/soumyak/adpd/snp_lists/'+cluster+'.overlap.expanded.snps.hg38.bed',\n",
    "                       sep='\\t')\n",
    "    if not os.path.isdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/' + cluster):\n",
    "        os.mkdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/' + cluster)\n",
    "    orig_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/'\n",
    "    curr_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/'\n",
    "    for j in range(10):\n",
    "        with open(orig_basedir + cluster + '/' + 'shuf' + str(j) + '.initial.fasta', 'r') as infile, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.noneffect.fasta', 'w') as noneffect_file, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.effect.fasta', 'w') as effect_file:\n",
    "            init_seqs = infile.readlines()\n",
    "            for index, row in snps.iterrows():\n",
    "                rsid = row['rsid']\n",
    "                noneffect = row['noneffect']\n",
    "                effect = row['effect']\n",
    "                if effect.upper() in bases and noneffect.upper() in bases:\n",
    "                    noneffect_seq_name = init_seqs[(2 * index)].strip() + '_1kb_noneffect'\n",
    "                    noneffect_seq = init_seqs[(2 * index) + 1][:499] + noneffect + init_seqs[(2 * index) + 1][500:]\n",
    "                    noneffect_seq = noneffect_seq.strip()\n",
    "                    effect_seq_name = init_seqs[(2 * index)].strip() + '_1kb_effect'\n",
    "                    effect_seq = init_seqs[(2 * index) + 1][:499] + effect + init_seqs[(2 * index) + 1][500:]\n",
    "                    effect_seq = effect_seq.strip()\n",
    "                    assert len(noneffect_seq) == 1000\n",
    "                    assert len(noneffect_seq) == len(effect_seq)\n",
    "                    noneffect_file.write(noneffect_seq_name + '\\n')\n",
    "                    noneffect_file.write(noneffect_seq + '\\n')\n",
    "                    effect_file.write(effect_seq_name + '\\n')\n",
    "                    effect_file.write(effect_seq + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 200bp Subsets of Shuffled Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    snps = pd.read_csv('/mnt/lab_data3/soumyak/adpd/snp_lists/'+cluster+'.overlap.expanded.snps.hg38.bed',\n",
    "                       sep='\\t')\n",
    "    if not os.path.isdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_200bp_fasta/' + cluster):\n",
    "        os.mkdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_200bp_fasta/' + cluster)\n",
    "    orig_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/'\n",
    "    curr_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_200bp_fasta/'\n",
    "    for j in range(10):\n",
    "        with open(orig_basedir + cluster + '/' + 'shuf' + str(j) + '.initial.fasta', 'r') as infile, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.noneffect.fasta', 'w') as noneffect_file, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.effect.fasta', 'w') as effect_file:\n",
    "            init_seqs = infile.readlines()\n",
    "            for index, row in snps.iterrows():\n",
    "                rsid = row['rsid']\n",
    "                noneffect = row['noneffect']\n",
    "                effect = row['effect']\n",
    "                if effect.upper() in bases and noneffect.upper() in bases:\n",
    "                    noneffect_seq_name = init_seqs[(2 * index)].strip() + '_200bp_noneffect'\n",
    "                    noneffect_seq = init_seqs[(2 * index) + 1][400:499] + noneffect + init_seqs[(2 * index) + 1][500:600]\n",
    "                    noneffect_seq = noneffect_seq.strip()\n",
    "                    effect_seq_name = init_seqs[(2 * index)].strip() + '_200bp_effect'\n",
    "                    effect_seq = init_seqs[(2 * index) + 1][400:499] + effect + init_seqs[(2 * index) + 1][500:600]\n",
    "                    effect_seq = effect_seq.strip()\n",
    "                    assert len(noneffect_seq) == 200\n",
    "                    assert len(noneffect_seq) == len(effect_seq)\n",
    "                    noneffect_file.write(noneffect_seq_name + '\\n')\n",
    "                    noneffect_file.write(noneffect_seq + '\\n')\n",
    "                    effect_file.write(effect_seq_name + '\\n')\n",
    "                    effect_file.write(effect_seq + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 50bp Subsets of Shuffled Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    snps = pd.read_csv('/mnt/lab_data3/soumyak/adpd/snp_lists/'+cluster+'.overlap.expanded.snps.hg38.bed',\n",
    "                       sep='\\t')\n",
    "    if not os.path.isdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_fasta/' + cluster):\n",
    "        os.mkdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_fasta/' + cluster)\n",
    "    orig_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/'\n",
    "    curr_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_fasta/'\n",
    "    for j in range(10):\n",
    "        with open(orig_basedir + cluster + '/' + 'shuf' + str(j) + '.initial.fasta', 'r') as infile, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.noneffect.fasta', 'w') as noneffect_file, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.effect.fasta', 'w') as effect_file:\n",
    "            init_seqs = infile.readlines()\n",
    "            for index, row in snps.iterrows():\n",
    "                rsid = row['rsid']\n",
    "                noneffect = row['noneffect']\n",
    "                effect = row['effect']\n",
    "                if effect.upper() in bases and noneffect.upper() in bases:\n",
    "                    noneffect_seq_name = init_seqs[(2 * index)].strip() + '_50bp_noneffect'\n",
    "                    noneffect_seq = init_seqs[(2 * index) + 1][475:499] + noneffect + init_seqs[(2 * index) + 1][500:525]\n",
    "                    noneffect_seq = noneffect_seq.strip()\n",
    "                    effect_seq_name = init_seqs[(2 * index)].strip() + '_50bp_effect'\n",
    "                    effect_seq = init_seqs[(2 * index) + 1][475:499] + effect + init_seqs[(2 * index) + 1][500:525]\n",
    "                    effect_seq = effect_seq.strip()\n",
    "                    assert len(noneffect_seq) == 50\n",
    "                    assert len(noneffect_seq) == len(effect_seq)\n",
    "                    noneffect_file.write(noneffect_seq_name + '\\n')\n",
    "                    noneffect_file.write(noneffect_seq + '\\n')\n",
    "                    effect_file.write(effect_seq_name + '\\n')\n",
    "                    effect_file.write(effect_seq + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 50bp Subsets of Shuffled Sequences with Same ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "Cluster2\n",
      "Cluster3\n",
      "Cluster4\n",
      "Cluster5\n",
      "Cluster6\n",
      "Cluster7\n",
      "Cluster8\n",
      "Cluster9\n",
      "Cluster10\n",
      "Cluster11\n",
      "Cluster12\n",
      "Cluster13\n",
      "Cluster14\n",
      "Cluster15\n",
      "Cluster16\n",
      "Cluster17\n",
      "Cluster18\n",
      "Cluster19\n",
      "Cluster20\n",
      "Cluster21\n",
      "Cluster22\n",
      "Cluster23\n",
      "Cluster24\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    cluster = 'Cluster' + str(i)\n",
    "    print(cluster)\n",
    "    snps = pd.read_csv('/mnt/lab_data3/soumyak/adpd/snp_lists/'+cluster+'.overlap.expanded.snps.hg38.bed',\n",
    "                       sep='\\t')\n",
    "    if not os.path.isdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_sameID_fasta/' + cluster):\n",
    "        os.mkdir('/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_sameID_fasta/' + cluster)\n",
    "    orig_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_1kb_fasta/'\n",
    "    curr_basedir = '/oak/stanford/groups/akundaje/projects/alzheimers_parkinsons/shuffled_50bp_sameID_fasta/'\n",
    "    for j in range(10):\n",
    "        with open(orig_basedir + cluster + '/' + 'shuf' + str(j) + '.initial.fasta', 'r') as infile, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.noneffect.fasta', 'w') as noneffect_file, \\\n",
    "             open(curr_basedir + cluster + '/' + 'shuf' + str(j) + '.effect.fasta', 'w') as effect_file:\n",
    "            init_seqs = infile.readlines()\n",
    "            for index, row in snps.iterrows():\n",
    "                rsid = row['rsid']\n",
    "                noneffect = row['noneffect']\n",
    "                effect = row['effect']\n",
    "                if effect.upper() in bases and noneffect.upper() in bases:\n",
    "                    noneffect_seq_name = init_seqs[(2 * index)].strip() + '_50bp'\n",
    "                    noneffect_seq = init_seqs[(2 * index) + 1][475:499] + noneffect + init_seqs[(2 * index) + 1][500:525]\n",
    "                    noneffect_seq = noneffect_seq.strip()\n",
    "                    effect_seq_name = init_seqs[(2 * index)].strip() + '_50bp'\n",
    "                    effect_seq = init_seqs[(2 * index) + 1][475:499] + effect + init_seqs[(2 * index) + 1][500:525]\n",
    "                    effect_seq = effect_seq.strip()\n",
    "                    assert len(noneffect_seq) == 50\n",
    "                    assert len(noneffect_seq) == len(effect_seq)\n",
    "                    noneffect_file.write(noneffect_seq_name + '\\n')\n",
    "                    noneffect_file.write(noneffect_seq + '\\n')\n",
    "                    effect_file.write(effect_seq_name + '\\n')\n",
    "                    effect_file.write(effect_seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
